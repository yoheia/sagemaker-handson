{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch の学習と推論を Amazon SageMaker で行う\n",
    "\n",
    "MNISTデータセットを対象にAmazon SageMakerとPyTorchを利用してCNNの学習と推論を行います。学習の方法として以下の3種類を試します。\n",
    "- 単一または複数ノードによる学習: 高性能なトレーニングインスタンスを1つまたは複数立ち上げて学習を行います。\n",
    "- ハイパーパラメータ最適化: 単一ノードにおける学習でHPO (Hyper-Parameter Optimization: ハイパーパラメータ最適化）を行います。\n",
    "- ローカルモード: ノートブックインスタンスで学習します。追加のインスタンス立ち上げが不要で、開発時のデバッグに有用です。\n",
    "\n",
    "\n",
    "## 目次\n",
    "1. [準備](#準備)\n",
    "2. [データの取得とS3へのアップロード](#データの取得とS3へのアップロード)\n",
    "3. [エントリーポイント](#エントリーポイント)\n",
    "4. [モデルの学習](#モデルの学習)\n",
    "    1. [単一または複数ノードによる学習](#単一または複数ノードによる学習)\n",
    "    2. [ハイパーパラメータの最適化](#ハイパーパラメータの最適化)\n",
    "    3. [ローカルモード](#ローカルモード)\n",
    "5. [学習結果の可視化](#学習結果の可視化)\n",
    "6. [ハイパーパラメータのチューニング結果](#ハイパーパラメータのチューニング結果)\n",
    "7. [モデルの推論を実行](#モデルの推論を実行)\n",
    "8. [エンドポイントの削除](#エンドポイントの削除)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備\n",
    "\n",
    "ローカルモードを実行するため、いくつかのパッケージを事前インストールする必要があります。そのためのスクリプト`setup.sh`を用意しているので実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの取得とS3へのアップロード\n",
    "\n",
    "ここでは、`PyTorch` でサポートされている関数を使って、MNIST データをダウンロードします。SageMaker の学習時に利用するデータは、S3 に置く必要があります。ここでは、ローカルにダウンロードした MNIST データを npz 形式で固めてから、SageMaker のラッパー関数を使って S3 にアップロードします。\n",
    "\n",
    "デフォルトでは SageMaker は `sagemaker-{region}-{your aws account number}` というバケットを使用します。当該バケットがない場合には、自動で新しく作成します。`upload_data()` メソッドの引数に bucket=XXXX という形でデータを配置するバケットを指定することも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "datasets.MNIST('data', download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "]))\n",
    "\n",
    "\n",
    "prefix = 'sagemaker/DEMO-pytorch-mnist'\n",
    "inputs = sagemaker_session.upload_data(path='data', key_prefix=prefix)\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エントリーポイント\n",
    "\n",
    "SageMakerで、Pytroch、Chainer、Tensorflowなどのフレームワークを利用して深層学習を行うためには、このnotebook以外に**エントリーポイントを作成する必要があります**。エントリーポイントとはモデルや学習方法を記述した.pyファイルで、このnotebookには`mnist.py`というエントリーポイントを同じフォルダに用意しています。ノートブックインスタンスでfit関数を呼び出すと、エントリーポイントに沿って学習が行われます。\n",
    "\n",
    "PyTorchを利用する場合は、エントリーポイントの`__main__`関数内にモデルの記述や学習方法を記載すればよく、SageMakerを使う以前のPyTorchのコードを概ねそのまま利用することができます。また、環境変数経由で入力データの場所や GPU の数などを取得することが可能です。これは `argparse` 経由で `main` 関数内で受け取ることができます。詳細は[こちら](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/pytorch/README.rst)をご覧ください。\n",
    "\n",
    "また推論時の処理は、`model_fn` で学習済みモデルをロードする部分だけ記述する必要があります。その他オプションで、前処理、推論処理、後処理部分を `input_fn`、 `predict_fn`、 `output_fn` で書くこともできます。デフォルトでは、`application/x-npy` Content-Typeで指定される、NumPy 配列を入力として受け取ります。 \n",
    "\n",
    "以下のセルを実行してエントリーポイントの中身を表示してみます。すると、`class Net(nn.Module)`内でのCNNの定義、`__main__`の中に学習のコードが書かれていることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pygmentize 'mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習\n",
    "\n",
    "`Estimator` クラスの子クラスの `PyTorch` オブジェクトを作成し、`fit()` メソッドで学習ジョブを実行します。 `entry_point` で指定したローカルのスクリプトが、学習用のコンテナ内で実行されます。また合わせてローカルの `source_dir` を指定することで、依存するスクリプト群をコンテナにコピーして、学習時に使用することが可能です。`source_dir`にrequirements.txtという名前で、pipでインストール可能なライブラリのリストを入れておくと、学習時にpipで自動インストールされます。\n",
    "\n",
    "### 単一または複数ノードによる学習\n",
    "\n",
    "単一ノードで学習したい場合は、`train_instance_count=1`として、学習用インスタンスを`instance_type`に指定します。複数ノードによる学習は、`train_instance_count`を1より大きくすることで実行できます。複数ノードの場合には、エントリーポイントに分散学習となるような実装が必要になります。PyTorchではCPUの分散学習のためにgloo、GPUの分散学習のためにncclを選ぶことができます。あとで学習の結果を参照するためにジョブの名前を記録しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type = 'ml.c4.xlarge'\n",
    "pytorch_estimator = PyTorch(entry_point='mnist.py',\n",
    "                    source_dir =\".\",\n",
    "                    role=sagemaker.get_execution_role(),\n",
    "                    framework_version='0.4.0',\n",
    "                    train_instance_count=2,\n",
    "                    train_instance_type=instance_type,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 6,\n",
    "                        'backend': 'gloo'\n",
    "                    })\n",
    "\n",
    "pytorch_estimator.fit({'training': inputs})\n",
    "\n",
    "# Keep the job name for checking training loss later \n",
    "training_job = pytorch_estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメータの最適化\n",
    "\n",
    "ハイパーパラメータの最適化は、fitする前に、以下のような処理を書くことによって実行できます。\n",
    "\n",
    "- ハイパーパラメータの探索条件の設定\n",
    "    - カテゴリ変数、連続変数、離散変数かどうか、探索範囲の指定を行います。\n",
    "- ハイパーパラメータを選択する基準（以下では、バリデーションデータに対する精度で選択）\n",
    "    - エントリーポイント内のPrintReportでバリデーションデータに対する精度を出力 \n",
    "    - ログからバリデーションデータに対する精度のみを抽出する正規表現を記述  \n",
    "    \n",
    "- 上記の探索範囲、選択基準、チューニングのために実行するジョブ数などを指定してHyperparameterTunerを定義\n",
    "\n",
    "ハンズオンの時間の都合上、以下では最適化のアルゴリズムをSGDかAdamのどちらかを選択するだけのチューニングを行います。\n",
    "チューニングのジョブを以下のページで確認することができます。`Completed`になるまで5分程度かかりますので、待たずに次のローカルモードに進みましょう。  \n",
    "https://ap-northeast-1.console.aws.amazon.com/sagemaker/home?region=ap-northeast-1#/hyper-tuning-jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from sagemaker.pytorch import PyTorch\n",
    "instance_type = 'ml.m4.xlarge'\n",
    "pytorch_estimator = PyTorch(entry_point='mnist.py',\n",
    "                    role=sagemaker.get_execution_role(),\n",
    "                    framework_version='0.4.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type=instance_type,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 6,\n",
    "                        'backend': 'gloo'\n",
    "                    })\n",
    "\n",
    "###Setting for hyper paramter optimization###\n",
    "from sagemaker.tuner import HyperparameterTuner,  CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "\n",
    "hyperparameter_ranges = {'optimizer': CategoricalParameter(['sgd', 'Adam'])}\n",
    "'''\n",
    "An example of further tuning:\n",
    "hyperparameter_ranges = {'optimizer': CategoricalParameter(['sgd', 'Adam']),\n",
    "                          'learning_rate': ContinuousParameter(0.01, 0.2),\n",
    "                          'num_epoch': IntegerParameter(3, 5)}\n",
    "'''\n",
    "\n",
    "objective_metric_name = 'Validation-accuracy'\n",
    "metric_definitions = [{'Name': 'Validation-accuracy',\n",
    "                       'Regex': 'Accuracy: ([0-9\\\\.]+)'}]\n",
    "\n",
    "tuner = HyperparameterTuner(pytorch_estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=2,\n",
    "                            max_parallel_jobs=2)\n",
    "##################################\n",
    "\n",
    "tuner.fit({'training': inputs})\n",
    "\n",
    "training_job_tuning = tuner.latest_tuning_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの自動選択\n",
    "\n",
    "SageMakerが指定できるハイパーパラメータは、いわゆるDeep Learningのハイパーパラメータ以外にも、様々なものを探索することができます。ここでは、複数のモデルを定義して、そのモデルの中から最善のものを選ぶために、ハイパーパラメータ最適化を利用してみたいと思います。`mnist.py`では畳み込み層2層のNetと畳み込み層3層のNet2を定義しています。ここで、`CategoricalParameter(['Net', 'Net2'])`と指定して、どちらかを選ぶようにします。指定したモデルが選択されるように`minist.py`の中には以下のようなコードを書いておき、あとは先ほどと同じ要領でHyperparameterTunerに対するfitを行います。\n",
    "\n",
    "```python\n",
    "if args.model == \"Net2\":\n",
    "    model = Net2().to(device)\n",
    "else:\n",
    "    model = Net().to(device)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Setting for hyper paramter optimization###\n",
    "from sagemaker.tuner import HyperparameterTuner,  CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "\n",
    "instance_type = 'ml.m4.xlarge'\n",
    "pytorch_estimator = PyTorch(entry_point='mnist.py',\n",
    "                    role=sagemaker.get_execution_role(),\n",
    "                    framework_version='0.4.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type=instance_type,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 6,\n",
    "                        'backend': 'gloo'\n",
    "                    })\n",
    "\n",
    "hyperparameter_ranges = {'model': CategoricalParameter(['Net', 'Net2'])}\n",
    "\n",
    "objective_metric_name = 'Validation-accuracy'\n",
    "metric_definitions = [{'Name': 'Validation-accuracy',\n",
    "                       'Regex': 'Accuracy: ([0-9\\\\.]+)'}]\n",
    "\n",
    "model_selector = HyperparameterTuner(pytorch_estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=2,\n",
    "                            max_parallel_jobs=2,\n",
    "                            base_tuning_job_name ='model-selector-mnist')\n",
    "##################################\n",
    "\n",
    "model_selector.fit({'training': inputs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ローカルモード\n",
    "\n",
    "ノートブックインスタンスのCPUで学習する場合は`instance_type = 'local'`、GPUで学習する場合は`local_gpu`を指定します。インスタンス数は、ノートブックインスタンスの数、すなわち1になるため、 `train_instance_count`に指定された値が1より大きい場合も1として扱われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "pytorch_estimator = PyTorch(entry_point='mnist.py',\n",
    "                    source_dir =\".\",\n",
    "                    role=sagemaker.get_execution_role(),\n",
    "                    framework_version='0.4.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type=instance_type,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 6,\n",
    "                        'backend': 'gloo'\n",
    "                    })\n",
    "\n",
    "\n",
    "pytorch_estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータ最適化結果の確認\n",
    "\n",
    "学習が終わったら結果を可視化してみましょう。その前に以下でチューニングのジョブが`complete`になっていることを確認します。チューニングのジョブの表で、先ほど実行したジョブの名前をクリックすると、トレーニングジョブのページに移動します。SGDとAdamのそれぞれの最適化を実行したジョブの結果が表示されており、それぞれの検証スコア（バリデーションデータに対する精度）が表示されていると思います。  \n",
    "https://ap-northeast-1.console.aws.amazon.com/sagemaker/home?region=ap-northeast-1#/hyper-tuning-jobs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`describe_training_job`を利用することで、ジョブの詳細を辞書形式で見ることができます。特に、チューニングジョブの詳細を見ることによって、ハイパーパラメータのチューニング結果を知ることができます。例えば、ハイパーパラメータ最適化によって、選択されたOptimizerを知りたい場合は、辞書の\\['HyperParameters'\\]\\['Optimizer'\\]を見ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "desc = tuner.sagemaker_session.sagemaker_client. \\\n",
    "           describe_training_job(TrainingJobName=tuner.best_training_job())\n",
    "selected_optimizer = desc['HyperParameters']['optimizer']\n",
    "print(selected_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの推論を実行\n",
    "\n",
    "\n",
    "推論を行うために学習したモデルをデプロイします。ここでは、ハイパーパラメータをチューニングした結果からデプロイしましょう。`deploy()` メソッドでは、デプロイ先エンドポイントのインスタンス数、インスタンスタイプを指定します。こちらもインスタンスタイプを `local` にすることで，このインスタンス内にエンドポイントを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "instance_type = 'ml.m4.xlarge'\n",
    "predictor = tuner.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デプロイが終わったら実際に手書き文字認識を行ってみましょう。最初はランダムに5枚選んで推論をしてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_dataset = datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "]))\n",
    "\n",
    "\n",
    "num_samples = 5\n",
    "indices = random.sample(range(len(test_dataset) - 1), num_samples)\n",
    "images = []\n",
    "labels = []\n",
    "for i in list(indices):\n",
    "    image, label = test_dataset[i] \n",
    "    images.append(image.data.numpy())\n",
    "    labels.append(label.data.numpy())\n",
    "    \n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1,num_samples,i+1)\n",
    "    plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(labels[i])\n",
    "    plt.axis('off')\n",
    "\n",
    "prediction = predictor.predict(images)\n",
    "predicted_label = prediction.argmax(axis=1)\n",
    "print('The predicted labels are: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルを実行すると、HTMLのcanvasを表示して、枠内に手書きの数字を書くことができます。さらに次のセルを実行すると、キャンバスに書かれた数字に対して、エンドポイントで予測が実行されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open(\"input.html\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = np.array(data, dtype=np.float32)\n",
    "prediction = predictor.predict([image])\n",
    "predicted_label = prediction.argmax(axis=1)[0]\n",
    "print('What you wrote is: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エンドポイントの削除\n",
    "\n",
    "不要になったエンドポイントを削除します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
